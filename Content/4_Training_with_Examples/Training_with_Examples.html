
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Créer une IA &#8212; Contenu pilote</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/book.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/gtag_0.js"></script>
    <script src="../../_static/gtag_1.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script >const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5. Utiliser une IA dans un programme" href="../5_Programming_with_AI/Programming_with_AI.html" />
    <link rel="prev" title="3. Données et prédictions" href="../3_Data_and_Predictions/Data_and_Predictions.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/robot.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Contenu pilote</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../README.html">
   Aperçu
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../1_Introduction_AI/Introduction_AI.html">
   1. C’est quoi l’Intelligence Artificielle ?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../2_Learning_Algorithm/Learning_Algorithm.html">
   2. Algorithme d’apprentissage
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../3_Data_and_Predictions/Data_and_Predictions.html">
   3. Données et prédictions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Créer une IA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../5_Programming_with_AI/Programming_with_AI.html">
   5. Utiliser une IA dans un programme
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../6_Bias_in_AI/Bias_in_AI.html">
   6. Le biais dans l’IA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Additional_Resources/Additional_Resources.html">
   7. Aller plus loin
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Content/4_Training_with_Examples/Training_with_Examples.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/lascientotheque/fetchbot-fr"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/lascientotheque/fetchbot-fr/issues/new?title=Issue%20on%20page%20%2FContent/4_Training_with_Examples/Training_with_Examples.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/lascientotheque/fetchbot-fr/edit/main/Content/4_Training_with_Examples/Training_with_Examples.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objectif">
   4.1. Objectif
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   4.2. Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#teachable-machine">
   4.3. Teachable machine
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interface-pour-entrainer-le-modele">
   4.4. Interface pour entraîner le modèle
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#choix-des-classes">
   4.5. Choix des classes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exemple-pour-un-classificateur-de-visages">
   4.6. Exemple pour un classificateur de visages
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#entrainement-et-test-du-modele">
   4.7. Entraînement et test du modèle
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exportation-du-modele">
   4.8. Exportation du modèle
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#export-du-modele-pour-une-utilisation-avec-scratch-adacraft">
     4.8.1. Export du modèle pour une utilisation avec Scratch (Adacraft)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#export-du-modele-pour-une-utilisation-avec-python">
     4.8.2. Export du modèle pour une utilisation avec Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reconnaissance-de-tubes-sur-un-sol-martien">
   4.9. Reconnaissance de tubes sur un sol martien
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ressources-complementaires">
   4.10. Ressources complémentaires
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="creer-une-ia">
<span id="image-recognition"></span><h1><span class="section-number">4. </span>Créer une IA<a class="headerlink" href="#creer-une-ia" title="Permalink to this headline">¶</a></h1>
<div class="section" id="objectif">
<h2><span class="section-number">4.1. </span>Objectif<a class="headerlink" href="#objectif" title="Permalink to this headline">¶</a></h2>
<p>Découvrir l’apprentissage automatique en entraînant un système de reconnaissance d’images avec l’outil en ligne ‘Teachable Machine’ de Google.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Âge</p></td>
<td class="text-align:left"><p>10 à 18 ans</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Notions abordées</p></td>
<td class="text-align:left"><p>Intelligence artificielle, apprentissage automatique, classification d’images, modèle de prédictions.</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Durée</p></td>
<td class="text-align:left"><p>2 heures</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Dispositif pédagogiques</p></td>
<td class="text-align:left"><p>Par groupe de 2</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Matériel</p></td>
<td class="text-align:left"><p>Un laptop/tablette par groupe de 2, avec connexion à Internet</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Prérequis</p></td>
<td class="text-align:left"><p>Aucun</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="introduction">
<h2><span class="section-number">4.2. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>La reconnaissance d’images par un ordinateur est une forme d’intelligence artificelle basée sur l’apprentissage automatique: Des exemples d’images de différentes catégories sont montrés à l’ordinateur, et un algorithme d’apprentissage est utilisé pour permettre à l’ordinateur de reconnaître les différentes catégories.</p>
<p>Vocabulaire utile:</p>
<ul class="simple">
<li><p>Les catégories d’images à reconnaître (sourire, grimace, objet, etc …) sont appelées <em>classes</em></p></li>
<li><p>L’ensemble des exemples des différentes classes que l’on utilise pour l’apprentissage s’appelle le <em>jeu de données d’apprentissage</em></p></li>
<li><p>L’apprentissage automatique est le terme employé lorsque l’on montre des exemples de ce que l’ordinateur doit apprendre à reconnaître</p></li>
<li><p>Le système de reconnaissance est plus couramment appelé <em>modèle de prédiction</em>.</p></li>
</ul>
<p>Dans le cas de la classification d’images, un modèle de prédiction est donc entrainé à reconnaître différentes classes d’images à partir d’un jeu de données d’apprentissage.</p>
<p>L’outil que tu utiliseras ici pour entraîner le modèle d’apprentissage automatique est la Teachable Machine, qui permet d’entraîner facilement un modèle de reconnaissance d’images en prenant des photos depuis la webcam. Tu associeras les images à des classes que le modèle devra reconnaître. La création de ton modèle (l’entraînement) sera fait sur le cloud par un service de Google.</p>
<p>Nous te montrerons deux exemples: la reconnaissance de visages et la détection d’objet sur un sol martien. Une fois que tu auras compris comment se passe l’entraînement d’un modèle, tu pourras créer d’autres applications de reconnaissance, par exemple pour reconnaître des objects, des émotions sur un visage, etc…</p>
<p>Ce tutoriel te montrera aussi comment tester ton ‘modèle’ sur de nouvelles images, et exporter ton modèle pour pouvoir l’utiliser dans un programme Scratch ou Python.</p>
</div>
<div class="section" id="teachable-machine">
<h2><span class="section-number">4.3. </span>Teachable machine<a class="headerlink" href="#teachable-machine" title="Permalink to this headline">¶</a></h2>
<p>Va sur le site de la Teachable Machine à <a class="reference external" href="https://teachablemachine.withgoogle.com">https://teachablemachine.withgoogle.com</a>. Tu peux changer la langue dans la liste déroulante qui se trouve tout en bas de la page, à droite.</p>
<p>Clique sur “Commencer”.</p>
<a class="reference internal image-reference" href="../../_images/TM_1_Start.jpg"><img alt="../../_images/TM_1_Start.jpg" src="../../_images/TM_1_Start.jpg" style="width: 900px;" /></a>
<p>Dans la page “Nouveau projet”, clique sur “Projet image”.</p>
<a class="reference internal image-reference" href="../../_images/TM_2_Image_Project.jpg"><img alt="../../_images/TM_2_Image_Project.jpg" src="../../_images/TM_2_Image_Project.jpg" style="width: 900px;" /></a>
<p>Puis clique sur “Modèle d’image standard”.</p>
<a class="reference internal image-reference" href="../../_images/TM_3_Standard_Image_Model.jpg"><img alt="../../_images/TM_3_Standard_Image_Model.jpg" src="../../_images/TM_3_Standard_Image_Model.jpg" style="width: 900px;" /></a>
</div>
<div class="section" id="interface-pour-entrainer-le-modele">
<h2><span class="section-number">4.4. </span>Interface pour entraîner le modèle<a class="headerlink" href="#interface-pour-entrainer-le-modele" title="Permalink to this headline">¶</a></h2>
<p>Après avoir cliqué “Modèle d’image standard”, l’interface permettant de faire un entraînement s’affiche:</p>
<a class="reference internal image-reference" href="../../_images/TM_4_Start_Training.jpg"><img alt="../../_images/TM_4_Start_Training.jpg" src="../../_images/TM_4_Start_Training.jpg" style="width: 900px;" /></a>
<p>Elle est composée de trois parties:</p>
<ul class="simple">
<li><p>A gauche, tu peux ajouter des images pour différentes classes. Par défaut, l’interface te propose d’ajouter des images pour deux classes différentes, qui s’appellent ‘Class 1’ et ‘Class 2’. Tu peux ajouter des classes en cliquant sur ‘Ajouter une classe’ en bas.</p></li>
<li><p>Au milieu, le bouton ‘Entraînement’ te permet d’entraîner le modèle.</p></li>
<li><p>A droite, dans ‘Aperçu’, tu pourras tester et exporter ton modèle une fois que tu l’auras entraîné.</p></li>
</ul>
</div>
<div class="section" id="choix-des-classes">
<h2><span class="section-number">4.5. </span>Choix des classes<a class="headerlink" href="#choix-des-classes" title="Permalink to this headline">¶</a></h2>
<p>Le choix des classes dépend de ce que tu veux faire reconnaître à l’ordinateur. Nous allons ici te montrer deux exemples: Un classifieur qui reconnaît des visages, et un classifieur capable de retrouver des tubes sur un sol martien (ce classifieur pourra servir plus tard pour les activités liées à Mars et à la construction d’un rover).</p>
<p>Tu peux bien sûr entraîner ton classifieur à faire autre chose, comme reconnaître des objets, des fruits, ou des expressions de visages!</p>
<p>Pour l’entraînement, prends au moins quelques dizaines d’images. Renomme les classes comme tu le souhaite en cliquant sur l’icône de crayon associé à chaque classe, puis appuie sur l’icône de caméra pour prendre différentes images de la classe correspondante.</p>
<p>Lorsque tu cliqueras sur la caméra, il est possible que le navigateur Web te demande l’autorisation d’utiliser la caméra. Dans ce cas, autorise-le.</p>
</div>
<div class="section" id="exemple-pour-un-classificateur-de-visages">
<h2><span class="section-number">4.6. </span>Exemple pour un classificateur de visages<a class="headerlink" href="#exemple-pour-un-classificateur-de-visages" title="Permalink to this headline">¶</a></h2>
<p>Dans le cas d’un classifieur de visages, prends une vingtaine d’images pour chacun des visages à reconnaître. Ici, le mieux est de faire l’activité par deux, avec deux classes: Une classe pour ton visage, et l’autre classe pour le visage de celui avec qui tu fais l’activité. Pour les noms des classes, utilise simplement ton nom et celui de ton/ta camarade.</p>
<p>Veille ici à prendre des exemples aussi variés que possibles (position du visage par rapport à la caméra, conditions d’éclairage, fond de l’image) afin de rendre le système de reconnaissance le plus fiable possible.
Une fois qu’une vingtaine d’images ont été prises pour chacun de vos deux visages, l’interface ressemblera à ceci:</p>
<a class="reference internal image-reference" href="../../_images/TM_5_Emotions.jpg"><img alt="../../_images/TM_5_Emotions.jpg" src="../../_images/TM_5_Emotions.jpg" style="width: 900px;" /></a>
</div>
<div class="section" id="entrainement-et-test-du-modele">
<h2><span class="section-number">4.7. </span>Entraînement et test du modèle<a class="headerlink" href="#entrainement-et-test-du-modele" title="Permalink to this headline">¶</a></h2>
<p>Clique ensuite sur “Entraînement”. Cela prend en général moins d’une minute pour que l’entraînement se termine. Une fois celui-ci terminé, la partie de droite ‘Aperçu’ t’affichera l’image provenant de la webcam, et te permettra de tester ton modèle.</p>
<a class="reference internal image-reference" href="../../_images/TM_6_Emotions.jpg"><img alt="../../_images/TM_6_Emotions.jpg" src="../../_images/TM_6_Emotions.jpg" style="width: 900px;" /></a>
<p>Questions à te poser :</p>
<ul class="simple">
<li><p>Que se passe-t-il si aucun visage n’est présent, ou le visage de quelqu’un d’autre ?</p></li>
<li><p>Que se passe-t-il lorsque vos deux visages sont présents à la caméra ?</p></li>
</ul>
<p>On peut voir que le système n’ayant appris que deux classes correspondant à deux visages, il essaiera toujours d’associer ce qu’il perçoit à l’un des deux visages, même si ceux-ci ne sont pas présents (ou qu’il sont présents tous les deux). Pour améliorer le système, d’autres classes peuvent être ajoutées (par exemple une classe ‘autre’, contenant des exemples avec aucun visage, ou des deux visages en même temps).</p>
</div>
<div class="section" id="exportation-du-modele">
<h2><span class="section-number">4.8. </span>Exportation du modèle<a class="headerlink" href="#exportation-du-modele" title="Permalink to this headline">¶</a></h2>
<p>Exporte ton modèle pour pouvoir l’utiliser ensuite avec Scracth (Adacraft) ou Python. Pour cela, clique sur ‘Exporter’. La fenêtre suivante apparaît:</p>
<a class="reference internal image-reference" href="../../_images/TM_7_Export.jpg"><img alt="../../_images/TM_7_Export.jpg" src="../../_images/TM_7_Export.jpg" style="width: 600px;" /></a>
<div class="section" id="export-du-modele-pour-une-utilisation-avec-scratch-adacraft">
<h3><span class="section-number">4.8.1. </span>Export du modèle pour une utilisation avec Scratch (Adacraft)<a class="headerlink" href="#export-du-modele-pour-une-utilisation-avec-scratch-adacraft" title="Permalink to this headline">¶</a></h3>
<p>Dans l’onglet ‘Tensorflow.js’, clique sur ‘Importer le modèle’. Cela prend environ deux minutes. Un lien vers le modèle apparaîtra comme ci-dessous:</p>
<a class="reference internal image-reference" href="../../_images/TM_8_Export_Scratch.jpg"><img alt="../../_images/TM_8_Export_Scratch.jpg" src="../../_images/TM_8_Export_Scratch.jpg" style="width: 600px;" /></a>
<p>Copie-le pour pouvoir le réutiliser plus tard dans le bloc Modèle d’Adacraft (tu peux aussi cliquer sur ‘Copier’ en bas à droite de la fenêtre pour copier le lien, que tu pourras ensuite coller dans Adacraft).</p>
</div>
<div class="section" id="export-du-modele-pour-une-utilisation-avec-python">
<h3><span class="section-number">4.8.2. </span>Export du modèle pour une utilisation avec Python<a class="headerlink" href="#export-du-modele-pour-une-utilisation-avec-python" title="Permalink to this headline">¶</a></h3>
<p>Pour l’utilisation du modèle avec Python, il faut utiliser la version Tensorflow Lite du modèle. Pour cela, va dans l’onglet ‘Tensorflow Lite’, et sélectionne ‘Quantifiés’.</p>
<a class="reference internal image-reference" href="../../_images/TM_9_Export_Python.jpg"><img alt="../../_images/TM_9_Export_Python.jpg" src="../../_images/TM_9_Export_Python.jpg" style="width: 600px;" /></a>
<p>Clique ensuite sur ‘Télécharger mon modèle’. Tu devras attendre environ 30 secondes pour que le modèle soit converti. Une fenêtre apparaîtra ensuite pour te permettre de télécharger un fichier s’appelant ‘converted_tflite.zip’, qui fait environ 2 mégaoctets. Télécharge le ficher en ouvrant l’archive ‘zip’. L’archive contient deux fichiers:</p>
<ul class="simple">
<li><p>Un ficher texte ‘labels.txt’</p></li>
<li><p>Un ficher ‘model.tflite’ qui pourra être ouvert par Python pour utiliser le modèle.</p></li>
</ul>
<p>Note: Si tu as un Coral, dans l’onglet ‘Tensorflow Lite’, sélectionne ‘EdgeTPU’, puis ‘Télécharger mon modèle’.</p>
</div>
</div>
<div class="section" id="reconnaissance-de-tubes-sur-un-sol-martien">
<h2><span class="section-number">4.9. </span>Reconnaissance de tubes sur un sol martien<a class="headerlink" href="#reconnaissance-de-tubes-sur-un-sol-martien" title="Permalink to this headline">¶</a></h2>
<p>Le second exemple que nous te donnons a pour but de faire un classifieur capable de dire si un tube est présent sur un sol martien. On distingue donc deux classes: Soit l’image perçue par la caméra contient un échantillon (un tube contenant des poussières de sol martien), soit elle n’en contient pas. Nous appellerons la première classe “Tube”, et la seconde classe “Autre”.</p>
<p>Pour faire l’entraînement, imprime au préalable l’image ci-dessous. On y voit un tube posé sur un sol martien (le tube est à peu près au centre).</p>
<a class="reference internal image-reference" href="../../_images/martian-soil-with-tube.jpg"><img alt="../../_images/martian-soil-with-tube.jpg" src="../../_images/martian-soil-with-tube.jpg" style="width: 900px;" /></a>
<p>Note : Plutôt que l’image de sol martien avec le tube, tu peux utiliser directement un objet que tu as à portée de main, tel qu’un crayon, une boîte, ou autre.</p>
<p>Les étapes sont ensuite les même que précédemment, pour entraîner, tester et exporter le modèle.</p>
<p>Pour l’entraînement, définis deux classes: ‘Tube’ et ‘Autre’. Pour la classe’ Autre’, ajoute des photos avec la webcam de parties de l’image où seul le sol est présent pour la classe sol, ou des photos de toi devant la caméra. Pour la classe ‘Tube’, prends des photos de l’image imprimée sur lesquelles le tube est visible. Une fois les photos prises pour les deux classes, tu devrais obtenir un jeu de données tel que celui illustré ci-dessous:</p>
<a class="reference internal image-reference" href="../../_images/TM_5_Tube_Other.jpg"><img alt="../../_images/TM_5_Tube_Other.jpg" src="../../_images/TM_5_Tube_Other.jpg" style="width: 900px;" /></a>
<p>Lance ensuite l’entraînement en cliquant sur le bouton ‘Entraînement’. Une fois celui-ci terminé (environ une minute), tu peux tester ton modèle en déplaçant la feuille devant la webcam. Vérifie que le modèle reconnaît correctement la présence du tube:</p>
<a class="reference internal image-reference" href="../../_images/TM_6_Tube_Other.jpg"><img alt="../../_images/TM_6_Tube_Other.jpg" src="../../_images/TM_6_Tube_Other.jpg" style="width: 900px;" /></a>
<p>Tu peux exporter ton modèle pour une utilisation vers Adacraft (Scratch) ou Python de la même manière que celle décrite ci-dessus pour la reconnaissance de visages.</p>
</div>
<div class="section" id="ressources-complementaires">
<h2><span class="section-number">4.10. </span>Ressources complémentaires<a class="headerlink" href="#ressources-complementaires" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://projects.raspberrypi.org/en/projects/image-id-coral/0">Image classification with Google Coral</a></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Content/4_Training_with_Examples"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../3_Data_and_Predictions/Data_and_Predictions.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>Données et prédictions</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../5_Programming_with_AI/Programming_with_AI.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Utiliser une IA dans un programme</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By bla<br/>
        
          <div class="extra_footer">
            <p>
License: <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
</p>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>
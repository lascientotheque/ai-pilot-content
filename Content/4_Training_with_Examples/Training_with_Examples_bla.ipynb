{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9224e35d",
   "metadata": {},
   "source": [
    "(Image_Recognition)=\n",
    "# Reconnaissance d'images avec la Teachable Machine\n",
    "\n",
    "**Objectif:** Découvrir l'apprentissage automatique en entraînant un système de reconnaissance d'images avec l'outil en ligne 'Teachable Machine' de Google. \n",
    "\n",
    "\n",
    "|||\n",
    ":--- | :--- |\n",
    "|Âge |10 à 18 ans|\n",
    "|Notions abordées|Intelligence artificielle, apprentissage automatique, classification d'images, modèle de prédictions.|\n",
    "| Durée| 2 heures|\n",
    "| Dispositif pédagogiques| Par groupe de 2|\n",
    "| Matériel| Un laptop/tablette par groupe de 2, avec connexion à Internet|\n",
    "| Prérequis| Aucun|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece832a0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "La reconnaissance d'images par un ordinateur est une forme d'intelligence artificelle basée sur l'apprentissage automatique: Des exemples d'images de différentes catégories sont montrés à l'ordinateur, et un algorithme d'apprentissage est utilisé pour permettre à l'ordinateur de reconnaître les différentes catégories. \n",
    "\n",
    "Vocabulaire utile:\n",
    "\n",
    "* Les catégories d'images à reconnaître (sourire, grimace, objet, etc ...) sont appelées *classes*\n",
    "* L'ensemble des exemples des différentes classes que l'on utilise pour l'apprentissage s'appelle le *jeu de données d'apprentissage*\n",
    "* L'apprentissage automatique est le terme employé lorsque l'on montre des exemples de ce que l'ordinateur doit apprendre à reconnaître\n",
    "* Le système de reconnaissance est plus couramment appelé *modèle de prédiction*.\n",
    "\n",
    "Dans le cas de la classification d'images, un modèle de prédiction est donc entrainé à reconnaître différentes classes d'images à partir d'un jeu de données d'apprentissage. \n",
    "\n",
    "L'outil que tu utiliseras ici pour entraîner le modèle d'apprentissage automatique est la Teachable Machine, qui permet d'entraîner facilement un modèle de reconnaissance d'images en prenant des photos depuis la webcam. Tu associeras les images à des classes que le modèle devra reconnaître. La création de ton modèle (l'entraînement) sera fait sur le cloud par un service de Google. \n",
    "\n",
    "Nous te montrerons deux exemples: la reconnaissance de visages et la détection d'objet sur un sol martien. Une fois que tu auras compris comment se passe l'entraînement d'un modèle, tu pourras créer d'autres applications de reconnaissance, par exemple pour reconnaître des objects, des émotions sur un visage, etc...\n",
    "\n",
    "Ce tutoriel te montrera aussi comment tester ton 'modèle' sur de nouvelles images, et exporter ton modèle pour pouvoir l'utiliser dans un programme Scratch ou Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e988c",
   "metadata": {},
   "source": [
    "## Teachable machine\n",
    "\n",
    "Va sur le site de la Teachable Machine à [https://teachablemachine.withgoogle.com](https://teachablemachine.withgoogle.com). Tu peux changer la langue dans la liste déroulante qui se trouve tout en bas de la page, à droite.\n",
    "\n",
    "\n",
    "\n",
    "Clique sur \"Commencer\".\n",
    "\n",
    "<img src=\"images/localisation/TM_1_Start.jpg\" width=\"900\"/> \n",
    "\n",
    "Dans la page \"Nouveau projet\", clique sur \"Projet image\".\n",
    "\n",
    "<img src=\"images/localisation/TM_2_Image_Project.jpg\" width=\"900\"/> \n",
    "\n",
    "Puis clique sur \"Modèle d'image standard\".\n",
    "\n",
    "<img src=\"images/localisation/TM_3_Standard_Image_Model.jpg\" width=\"900\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1b659",
   "metadata": {},
   "source": [
    "## Interface pour entraîner le modèle\n",
    "\n",
    "Après avoir cliqué \"Modèle d'image standard\", l'interface permettant de faire un entraînement s'affiche:\n",
    "\n",
    "\n",
    "<img src=\"images/localisation/TM_4_Start_Training.jpg\" width=\"900\"/> \n",
    "\n",
    "\n",
    "Elle est composée de trois parties:\n",
    "\n",
    "* A gauche, tu peux ajouter des images pour différentes classes. Par défaut, l'interface te propose d'ajouter des images pour deux classes différentes, qui s'appellent 'Class 1' et 'Class 2'. Tu peux ajouter des classes en cliquant sur 'Ajouter une classe' en bas. \n",
    "* Au milieu, le bouton 'Entraînement' te permet d'entraîner le modèle.\n",
    "* A droite, dans 'Aperçu', tu pourras tester et exporter ton modèle une fois que tu l'auras entraîné. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b88571",
   "metadata": {},
   "source": [
    "## Choix des classes\n",
    "\n",
    "Le choix des classes dépend de ce que tu veux faire reconnaître à l'ordinateur. Nous allons ici te montrer deux exemples: Un classifieur qui reconnaît des visages, et un classifieur capable de retrouver des tubes sur un sol martien (ce classifieur pourra servir plus tard pour les activités liées à Mars et à la construction d'un rover). \n",
    "\n",
    "Tu peux bien sûr entraîner ton classifieur à faire autre chose, comme reconnaître des objets, des fruits, ou des expressions de visages! \n",
    "\n",
    "Pour l'entraînement, prends au moins quelques dizaines d'images. Renomme les classes comme tu le souhaite en cliquant sur l'icône de crayon associé à chaque classe, puis appuie sur l'icône de caméra pour prendre différentes images de la classe correspondante. \n",
    "\n",
    "Lorsque tu cliqueras sur la caméra, il est possible que le navigateur Web te demande l'autorisation d'utiliser la caméra. Dans ce cas, autorise-le.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794faa7a",
   "metadata": {},
   "source": [
    "## Exemple pour un classificateur de visages\n",
    "\n",
    "Dans le cas d’un classifieur de visages, prends une vingtaine d’images pour chacun des visages à reconnaître. Ici, le mieux est de faire l’activité par deux, avec deux classes: Une classe pour ton visage, et l'autre classe pour le visage de celui avec qui tu fais l'activité. Pour les noms des classes, utilise simplement ton nom et celui de ton/ta camarade. \n",
    "\n",
    "Veille ici à prendre des exemples aussi variés que possibles (position du visage par rapport à la caméra, conditions d’éclairage, fond de l’image) afin de rendre le système de reconnaissance le plus fiable possible.\n",
    "Une fois qu’une vingtaine d’images ont été prises pour chacun de vos deux visages, l’interface ressemblera à ceci:\n",
    "\n",
    "\n",
    "<img src=\"images/localisation/TM_5_Emotions.jpg\" width=\"900\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8c542",
   "metadata": {},
   "source": [
    "## Entraînement et test du modèle\n",
    "\n",
    "Clique ensuite sur \"Entraînement\". Cela prend en général moins d'une minute pour que l'entraînement se termine. Une fois celui-ci terminé, la partie de droite 'Aperçu' t'affichera l'image provenant de la webcam, et te permettra de tester ton modèle.\n",
    "\n",
    "<img src=\"images/localisation/TM_6_Emotions.jpg\" width=\"900\"/> \n",
    "\n",
    "\n",
    "Questions à te poser :\n",
    "\n",
    "* Que se passe-t-il si aucun visage n’est présent, ou le visage de quelqu'un d'autre ? \n",
    "* Que se passe-t-il lorsque vos deux visages sont présents à la caméra ?\n",
    "\n",
    "On peut voir que le système n’ayant appris que deux classes correspondant à deux visages, il essaiera toujours d’associer ce qu’il perçoit à l’un des deux visages, même si ceux-ci ne sont pas présents (ou qu’il sont présents tous les deux). Pour améliorer le système, d’autres classes peuvent être ajoutées (par exemple une classe ‘autre’, contenant des exemples avec aucun visage, ou des deux visages en même temps).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3a0b0",
   "metadata": {},
   "source": [
    "## Exportation du modèle\n",
    "\n",
    "Exporte ton modèle pour pouvoir l'utiliser ensuite avec Scracth (Adacraft) ou Python. Pour cela, clique sur 'Exporter'. La fenêtre suivante apparaît:\n",
    "\n",
    "<img src=\"images/localisation/TM_7_Export.jpg\" width=\"600\"/> \n",
    "\n",
    "### Export du modèle pour une utilisation avec Scratch (Adacraft)\n",
    "\n",
    "Dans l'onglet 'Tensorflow.js', clique sur 'Importer le modèle'. Cela prend environ deux minutes. Un lien vers le modèle apparaîtra comme ci-dessous:\n",
    "\n",
    "<img src=\"images/localisation/TM_8_Export_Scratch.jpg\" width=\"600\"/> \n",
    "\n",
    "Copie-le pour pouvoir le réutiliser plus tard dans le bloc Modèle d'Adacraft (tu peux aussi cliquer sur 'Copier' en bas à droite de la fenêtre pour copier le lien, que tu pourras ensuite coller dans Adacraft).\n",
    "\n",
    "### Export du modèle pour une utilisation avec Python\n",
    "\n",
    "Pour l'utilisation du modèle avec Python, il faut utiliser la version Tensorflow Lite du modèle. Pour cela, va dans l'onglet 'Tensorflow Lite', et sélectionne 'Quantifiés'.\n",
    "\n",
    "<img src=\"images/localisation/TM_9_Export_Python.jpg\" width=\"600\"/> \n",
    "\n",
    "Clique ensuite sur 'Télécharger mon modèle'. Tu devras attendre environ 30 secondes pour que le modèle soit converti. Une fenêtre apparaîtra ensuite pour te permettre de télécharger un fichier s'appelant 'converted_tflite.zip', qui fait environ 2 mégaoctets. Télécharge le ficher en ouvrant l'archive 'zip'. L'archive contient deux fichiers:\n",
    "\n",
    "* Un ficher texte 'labels.txt'\n",
    "* Un ficher 'model.tflite' qui pourra être ouvert par Python pour utiliser le modèle.\n",
    "\n",
    "Note: Si tu as un Coral, dans l'onglet 'Tensorflow Lite', sélectionne 'EdgeTPU', puis 'Télécharger mon modèle'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a70d6a",
   "metadata": {},
   "source": [
    "## Reconnaissance de tubes sur un sol martien\n",
    "\n",
    "Le second exemple que nous te donnons a pour but de faire un classifieur capable de dire si un tube est présent sur un sol martien. On distingue donc deux classes: Soit l'image perçue par la caméra contient un échantillon (un tube contenant des poussières de sol martien), soit elle n'en contient pas. Nous appellerons la première classe \"Tube\", et la seconde classe \"Autre\".\n",
    "\n",
    "Pour faire l'entraînement, imprime au préalable l'image ci-dessous. On y voit un tube posé sur un sol martien (le tube est à peu près au centre). \n",
    "\n",
    "<img src=\"images/martian-soil-with-tube.jpg\" width=\"900\"/> \n",
    "\n",
    "Note : Plutôt que l’image de sol martien avec le tube, tu peux utiliser directement un objet que tu as à portée de main, tel qu’un crayon, une boîte, ou autre.\n",
    "\n",
    "Les étapes sont ensuite les même que précédemment, pour entraîner, tester et exporter le modèle. \n",
    "\n",
    "Pour l'entraînement, définis deux classes: 'Tube' et 'Autre'. Pour la classe' Autre', ajoute des photos avec la webcam de parties de l'image où seul le sol est présent pour la classe sol, ou des photos de toi devant la caméra. Pour la classe 'Tube', prends des photos de l'image imprimée sur lesquelles le tube est visible. Une fois les photos prises pour les deux classes, tu devrais obtenir un jeu de données tel que celui illustré ci-dessous:\n",
    "\n",
    "<img src=\"images/localisation/TM_5_Tube_Other.jpg\" width=\"900\"/> \n",
    "\n",
    "Lance ensuite l'entraînement en cliquant sur le bouton 'Entraînement'. Une fois celui-ci terminé (environ une minute), tu peux tester ton modèle en déplaçant la feuille devant la webcam. Vérifie que le modèle reconnaît correctement la présence du tube:\n",
    "\n",
    "<img src=\"images/localisation/TM_6_Tube_Other.jpg\" width=\"900\"/> \n",
    "\n",
    "Tu peux exporter ton modèle pour une utilisation vers Adacraft (Scratch) ou Python de la même manière que celle décrite ci-dessus pour la reconnaissance de visages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666d833",
   "metadata": {},
   "source": [
    "## Ressources complémentaires\n",
    "\n",
    "* [Image classification with Google Coral](https://projects.raspberrypi.org/en/projects/image-id-coral/0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ea04d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
